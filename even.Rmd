---
title: "Even"
output: html_notebook
---

```{r}
library(tidyverse)
library(lme4)
library(merTools)
library(rlist)
library(caret)

setwd("D:\\Desktop\\even_dialects")
log_name <- "log.txt"
res_fname <- "facts_res.txt"
```

```{r}
# scr: список всех столбцов с признаками, из которых необходимо выделить относящиеся к части речи pos
# pos: часть речи
# return: список всех столбцов с признаками, относящимися к части речи pos
get_pos_features <- function(src, pos){
  return(src[which(endsWith(src, paste("-", as.character(pos), sep = "")))])
}

# возможные статусы регрессии:
# SUCC: подсчитана успешно
# NCON: регрессия не сошлась
# RES: reset
factor_status_fun <- function() {
    list(SUCC = "SUCCESS", ERR = "ERROR_OR_WARNING", RES = "RESET")
}

factor_status <- factor_status_fun()

# интерпретация summary регрессии
# fit: объект регрессии
# pvs: извлеченное из summary(fit) p-value
# return: один из трех статусов регрессии
get_factor_status <- function(fit){
  code <- fit@optinfo$conv$lme4$code
  if(is.null(code))
    return(list(factor_status$SUCC))
  return(list(factor_status$ERR, fit@optinfo$conv$lme4$messages))
}
```

```{r}
data <- read.csv("D:\\Desktop\\wordmor_table.csv", encoding = "UTF-8")
data <- data.frame(data)

# заголовки столбцов почему-то не загружаются правильно через read.csv
con = file("D:\\Desktop\\wordmor_table.csv", "r")
titles <- readLines(con, n = 1)
close(con)

colnames(data) <- strsplit(x = titles, split = '\\,')[[1]]

# исключение спикеров
ignore_speakers <- c('AL', 'NA', 'BP', 'children', 'VAK', 'NEN', 'T', '?', 'rh', 'TPA', 'R', 'LNZ', 'IAS')

data %>%
  filter(!(speaker %in% ignore_speakers)) -> data

levels(data$speaker) <- droplevels(data$speaker)

# исключение морфем
data %>%
  select(-corpus, -speaker, -pos) %>%
  colnames(.) -> morphems

ignore_cols <- c()

for(cn in morphems){
  if(grepl("?", cn, fixed = TRUE) | grepl("*", cn, fixed = TRUE)){
    ignore_cols <- c(ignore_cols, cn)
  }
}

data <- data[which(!(colnames(data) %in% ignore_cols))]

# исключение частей речи
data %>%
  filter(!(pos %in% c('?'))) -> data

data$pos %>%
  unique() %>%
  droplevels(.) -> parts_of_speech
```


```{r}
# таблица, в которую будут записываться результаты регрессий
# factor: показатель
# dialect_cor_pval_random: pval регрессии, где speaker -- случайный эффект модели
# dialect_cor_pval_bundled: pval регрессии, где speaker -- вложенный случайный эффект модели
# random_converged, bundled_converged: регрессия с соответствующей моделью сошлась
# f_pos: часть речи показателя
res_cols <- c("factor", "dialect_cor_pval_random", "dialect_cor_pval_bundled", "random_converged", "bundled_converged", "f_pos")
res <- data.frame(matrix(ncol = length(res_cols), nrow = 0))
colnames(res) <- res_cols

cnt <- 1
tot <- nrow(data)

for(pos in parts_of_speech){
  
  # список названий столбцов, в которых содержится информация о показателях, относящихся к определенной части речи
  relevant_cols <- get_pos_features(colnames(data), pos)
  
  # список строк, в которых содержится информация о показателях, относящихся к определенной части речи
  relevant_data <- data[data$pos == pos, ]
  
  for(i in seq(1, length(relevant_cols))){
    print(paste(cnt, '/', tot))
    cnt <- cnt + 1
    
    # факторизация
    relevant_data[, relevant_cols[i]] <- as.factor(relevant_data[, relevant_cols[i]])
    
    # сброс статуса регрессий
    factor_status_bundled <- factor_status$RES
    factor_status_random <- factor_status$RES
    
    # сброс pval
    pvs_bundled <- NA
    pvs_random <- NA
    
    # игнорирование ошибок. статус регрессий с предупреждениями (если есть) сохраняется в логе.
    tryCatch(
    {
      #..._bundled  
      fit_bundled <- glmer(relevant_data[, relevant_cols[i]] ~ corpus + (corpus|speaker), data = relevant_data, family = binomial,
                           control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=10000)))
      
      pvs_bundled <- unname(coef(summary(fit_bundled))[,'Pr(>|z|)'][2])
      
      factor_status_bundled <- get_factor_status(fit_bundled)
    },
    error = function(cond) {
        
    })
    
    capture.output(paste(relevant_cols[i], "[bundled]", ":", paste(unlist(factor_status_bundled))), file = log_name, append = TRUE)
    
    tryCatch(
    {
      #..._random  
      fit_random <- glmer(relevant_data[, relevant_cols[i]] ~ corpus + (1|speaker), data = relevant_data, family = binomial,
                          control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=10000)))
      
      pvs_random <- unname(coef(summary(fit_random))[,'Pr(>|z|)'][2])
      
      factor_status_random <- get_factor_status(fit_random)
    },
    error = function(cond) {
        
    })
    
    capture.output(paste(relevant_cols[i], "[random]", ":", paste(unlist(factor_status_random))), file = log_name, append = TRUE)
    
    # добавление в таблицу с результатами строки с информацией о текущем показателе
    res <- rbind(res, data.frame(factor = relevant_cols[i],
                                 # если регрессия не сошлась, в таблицу пишется NA
                                 dialect_cor_pval_bundled = ifelse(factor_status_bundled == factor_status$SUCC, pvs_bundled, NA),
                                 dialect_cor_pval_random = ifelse(factor_status_random == factor_status$SUCC, pvs_random, NA),
                                 bundled_converged = as.numeric(unlist(factor_status_bundled)[1] == factor_status$SUCC),
                                 random_converged = as.numeric(unlist(factor_status_random)[1] == factor_status$SUCC),
                                 f_pos = pos))
  }
}

```


```{r}
# получение именованного списка с суммарным количеством вхождений всех признаков, относящихся к данной части речи
# для статистики
pos_stats<-list()
for(pos in parts_of_speech){
  non_null_pos <- get_pos_features(colnames(data), pos)
  pos_stats <- c(pos_stats, sum(unlist(lapply(non_null_pos, function(non_null_pos) sum(data[, non_null_pos])))))
}

names(pos_stats) <- parts_of_speech
```


```{r}
# добавление в таблицу с результатами столбцов с частотой употребления в зависимости от диалекта
res %>%
  mutate(rel_freq_k = NA) %>%
  mutate(rel_freq_s = NA) -> res

# подсчет вхождений показателя по каждому диалекту
for(factor in res$factor){
  as.tibble(data[, factor]) %>%
    mutate(corpus = data$corpus) -> current_col
  current_col %>%
    filter(current_col[, 1] == 1) %>%
    count(corpus) %>%
    spread(key = "corpus", value = "n") -> count
  idx <- which(res$factor == factor)[1]
  for(corpus in colnames(count)){
    res[idx, corpus] <- count[, corpus]
  }
}

res$s[is.na(res$s)] <- 0
res$k[is.na(res$k)] <- 0

# подсчет частоты употребления показателя относительно других показателей этой части речи
for(factor in res$factor){
  idx <- which(res$factor == factor)[1]
  res[idx, "rel_freq_k"] <- res[idx, "k"] / as.numeric(pos_stats[as.character(res[idx, "f_pos"])])
  res[idx, "rel_freq_s"] <- res[idx, "s"] / as.numeric(pos_stats[as.character(res[idx, "f_pos"])])
  
  if(is.nan(res[idx, "rel_freq_k"]))
    res[idx, "rel_freq_k"] <- 0
  if(is.nan(res[idx, "rel_freq_s"]))
    res[idx, "rel_freq_s"] <- 0
}
```

```{r}
# экспорт
write.csv(res, file = res_fname)
```

```{r}
get_cis <- function(table_for_CI){
  table_for_CI %>%
    mutate(CI_intercept_l = NA, CI_intercept_r = NA, CI_b0_l = NA, CI_b0_r = NA, diff = NA) -> table_for_CI
  
  for(i in seq(1, length(table_for_CI$factor))){
    
    # список названий столбцов, в которых содержится информация о показателях, относящихся к определенной части речи
    relevant_cols <- get_pos_features(colnames(data), as.character(table_for_CI$f_pos[i]))
  
    # список строк, в которых содержится информация о показателях, относящихся к определенной части речи
    relevant_data <- data[as.character(data$pos) == as.character(table_for_CI$f_pos[i]), ]
    
    print(paste("Now at", i, '/', nrow(table_for_CI)))
    # факторизация
    relevant_data[, as.character(table_for_CI$factor[i])] <- as.factor(relevant_data[, as.character(table_for_CI$factor[i])])
    
    # сброс pval
    pval <- NA
    
    tryCatch(
      {
        # для bundled
        fit <- glmer(as.factor(relevant_data[, as.character(table_for_CI$factor[i])]) ~ corpus + (corpus|speaker),
                           data = relevant_data, family = binomial,
                           control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=10000)))
        # для random
        #fit <- glmer(as.factor(relevant_data[, as.character(table_for_CI$factor[i])]) ~ corpus + (1|speaker),
        #                  data = relevant_data, family = binomial,
        #                  control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun=10000)))
      
      pval <- unname(coef(summary(fit))[,'Pr(>|z|)'][2])

      table_for_CI$CI_intercept_l[i] <- unname(confint(fit, parm="beta_",method="Wald", level = 0.95)[1,])[1]
      table_for_CI$CI_intercept_r[i] <- unname(confint(fit, parm="beta_",method="Wald", level = 0.95)[1,])[2]
      table_for_CI$CI_b0_l[i] <- unname(confint(fit, parm="beta_",method="Wald", level = 0.95)[2,])[1]
      table_for_CI$CI_b0_r[i] <- unname(confint(fit, parm="beta_",method="Wald", level = 0.95)[2,])[2]
      
      table_for_CI$diff[i] <- abs(pval - table_for_CI[i, 2])
    },
    error = function(cond){ },
    finally = { })
  }
  
  return(table_for_CI)
}

res %>%
  filter(!is.na(dialect_cor_pval_bundled) & (dialect_cor_pval_bundled < 0.05) & (bundled_converged == 1)) %>%
  select(-dialect_cor_pval_random, -random_converged, -bundled_converged) -> res_bundled
# res %>%
#  filter(!is.na(dialect_cor_pval_random) & (dialect_cor_pval_random < 0.05) & (random_converged == 1)) %>%
#  select(-dialect_cor_pval_bundled, -random_converged, -bundled_converged) -> res_random

res_bundled <- get_cis(res_bundled)
#res_random <- get_cis(res_random)
```

#---------------------------------------

```{r}
write.csv(res_bundled, file = "bundled_CI.csv")
#write.csv(res_random, file = "random_CI.csv")
```
